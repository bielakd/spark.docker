<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="ChangeListManager">
    <list default="true" id="f2714388-760d-4745-8ee1-4dbd6fb557aa" name="Default Changelist" comment="" />
    <option name="EXCLUDED_CONVERTED_TO_IGNORED" value="true" />
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="CodeStyleSettingsInfer">
    <option name="done" value="true" />
  </component>
  <component name="ComposerSettings">
    <execution>
      <executable />
    </execution>
  </component>
  <component name="ProjectCodeStyleSettingsMigration">
    <option name="version" value="1" />
  </component>
  <component name="ProjectId" id="1SBgkZIOZLjFGdsuHmfwcFbtTCO" />
  <component name="PropertiesComponent">
    <property name="WebServerToolWindowFactoryState" value="false" />
    <property name="aspect.path.notification.shown" value="true" />
    <property name="last_opened_file_path" value="$PROJECT_DIR$" />
    <property name="nodejs_interpreter_path.stuck_in_default_project" value="undefined stuck path" />
    <property name="nodejs_npm_path_reset_for_default_project" value="true" />
  </component>
  <component name="RecentsManager">
    <key name="MoveFile.RECENT_KEYS">
      <recent name="$PROJECT_DIR$/../spark.jobs" />
    </key>
  </component>
  <component name="RunDashboard">
    <option name="ruleStates">
      <list>
        <RuleState>
          <option name="name" value="ConfigurationTypeDashboardGroupingRule" />
        </RuleState>
        <RuleState>
          <option name="name" value="StatusDashboardGroupingRule" />
        </RuleState>
      </list>
    </option>
  </component>
  <component name="RunManager" selected="Python.main">
    <configuration name="main" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="spark.jobs" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/../spark.jobs/src" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/../spark.jobs/src/main.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="docker-compose.yml: Compose Deployment" type="docker-deploy" factoryName="docker-compose.yml" server-name="Docker">
      <deployment type="docker-compose.yml">
        <settings>
          <option name="sourceFilePath" value="docker-compose.yml" />
        </settings>
      </deployment>
      <method v="2" />
    </configuration>
    <configuration name="docker-compose.yml.spark-worker-1: Compose Deployment" type="docker-deploy" factoryName="docker-compose.yml" temporary="true" server-name="Docker">
      <deployment type="docker-compose.yml">
        <settings>
          <option name="services">
            <list>
              <option value="spark-worker-1" />
            </list>
          </option>
          <option name="sourceFilePath" value="docker-compose.yml" />
        </settings>
      </deployment>
      <method v="2" />
    </configuration>
    <list>
      <item itemvalue="Docker.docker-compose.yml: Compose Deployment" />
      <item itemvalue="Docker.docker-compose.yml.spark-worker-1: Compose Deployment" />
      <item itemvalue="Python.main" />
    </list>
    <recent_temporary>
      <list>
        <item itemvalue="Python.main" />
        <item itemvalue="Docker.docker-compose.yml.spark-worker-1: Compose Deployment" />
      </list>
    </recent_temporary>
  </component>
  <component name="ServiceViewManager">
    <option name="allServicesViewState">
      <serviceView>
        <treeState>
          <expand>
            <path>
              <item name="services root" type="e789fda9:ObjectUtils$Sentinel" />
              <item name="com.intellij.execution.services.ServiceModel$ServiceNode@46f92f3d" type="9fbbdea:ServiceModel$ServiceNode" />
            </path>
          </expand>
          <select />
        </treeState>
      </serviceView>
    </option>
  </component>
  <component name="SvnConfiguration">
    <configuration />
  </component>
  <component name="TaskManager">
    <task active="true" id="Default" summary="Default task">
      <changelist id="f2714388-760d-4745-8ee1-4dbd6fb557aa" name="Default Changelist" comment="" />
      <created>1571042546482</created>
      <option name="number" value="Default" />
      <option name="presentableId" value="Default" />
      <updated>1571042546482</updated>
      <workItem from="1571042547780" duration="5397000" />
      <workItem from="1571056771459" duration="5065000" />
      <workItem from="1571136494227" duration="13255000" />
    </task>
    <servers />
  </component>
  <component name="TypeScriptGeneratedFilesManager">
    <option name="version" value="1" />
  </component>
  <component name="com.intellij.coverage.CoverageDataManagerImpl">
    <SUITE FILE_PATH="coverage/spark_docker$main.coverage" NAME="main Coverage Results" MODIFIED="1571206761948" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/../spark.jobs/src" />
  </component>
</project>